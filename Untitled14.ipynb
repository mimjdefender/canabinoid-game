{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrg8QTx/XLEb98DXEu9Qgd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimjdefender/canabinoid-game/blob/main/Untitled14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF pandas scikit-learn nltk pytesseract summa bertopic\n",
        "!sudo apt install tesseract-ocr\n",
        "\n",
        "import fitz  # PyMuPDF for PDF text extraction\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import os\n",
        "import re\n",
        "import pytesseract\n",
        "import spacy\n",
        "from PIL import Image\n",
        "from summa import summarizer\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Load spaCy's small English model for NER\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a PDF efficiently using PyMuPDF and falls back to OCR if necessary.\"\"\"\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as pdf_doc:\n",
        "        for page in pdf_doc:\n",
        "            # Fallback to OCR for image-based PDFs\n",
        "            pix = page.get_pixmap()\n",
        "            img_path = f\"page_{page.number}.png\"\n",
        "            pix.save(img_path)\n",
        "            text += pytesseract.image_to_string(Image.open(img_path))\n",
        "            os.remove(img_path)\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocesses text by lowercasing, tokenizing, and removing stopwords.\n",
        "    Adjusted to be less aggressive and preserve more meaningful words.\n",
        "    \"\"\"\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    # Reduce stopwords list - fine-tune this list as needed\n",
        "    stop_words = stop_words - set(['case', 'fine', 'amount', 'business', 'date'])\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    # Allow some punctuation - adjust this regex as needed\n",
        "    tokens = [word for word in tokens if re.match(r'\\b[a-zA-Z0-9.,!?]+\\b', word) and word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "def extract_entities(text):\n",
        "    \"\"\"Extracts case-related entities using spaCy NER.\"\"\"\n",
        "    doc = nlp(text)\n",
        "    entities = {\n",
        "        \"Case Number\": None,\n",
        "        \"Business Name\": None,\n",
        "        \"Fine Amount\": None,\n",
        "        \"Date\": None\n",
        "    }\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"MONEY\":\n",
        "            entities[\"Fine Amount\"] = ent.text\n",
        "        elif ent.label_ == \"ORG\":\n",
        "            entities[\"Business Name\"] = ent.text\n",
        "        elif ent.label_ == \"DATE\":\n",
        "            entities[\"Date\"] = ent.text\n",
        "        elif re.search(r'\\b(?:Case|Docket|File)\\s*#?\\s*(\\d+)', ent.text, re.IGNORECASE):\n",
        "            entities[\"Case Number\"] = ent.text\n",
        "    return entities\n",
        "\n",
        "def summarize_case(text, topic_model):\n",
        "    \"\"\"\n",
        "    Generates user-friendly and programmatic summaries.\n",
        "    Increased ratio for programmatic summary to potentially provide more content.\n",
        "    \"\"\"\n",
        "    summary_programmatic = summarizer.summarize(text, ratio=0.2)  # Increased ratio from 0.1\n",
        "    summary_user = summarizer.summarize(text, ratio=0.3)\n",
        "\n",
        "    # Extract dominant topic\n",
        "    topics, _ = topic_model.transform([text])\n",
        "    dominant_topic = topic_model.get_topic(topics[0])\n",
        "\n",
        "    # Include topic keywords in the user summary\n",
        "    if dominant_topic:\n",
        "        topic_keywords = \", \".join([word for word, _ in dominant_topic[:5]])\n",
        "        summary_user = f\"**Dominant Topic Keywords:** {topic_keywords}\\n\\n{summary_user}\"\n",
        "\n",
        "    return summary_programmatic, summary_user\n",
        "\n",
        "def detect_fines(text):\n",
        "    \"\"\"Extracts fine amounts with stricter criteria to improve accuracy.\"\"\"\n",
        "    # Modified pattern to capture potential false positives in a separate group\n",
        "    fine_amount_pattern = r\"(\\b[A-Za-z]{3}\\s\\d\\s[A-Za-z]{2}|\\b[A-Z0-9]{1,8})?\\s*(?:fine(?:\\s+\\w+){0,10})\\s*\\(\\s*Dollars\\s*\\$\\s*(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)\\s*\\)\"\n",
        "\n",
        "    fine_amounts_with_context = re.findall(fine_amount_pattern, text, re.IGNORECASE)\n",
        "\n",
        "    # Filter out matches with potential false positives\n",
        "    filtered_fine_amounts = [amount for context, amount in fine_amounts_with_context if not context]\n",
        "\n",
        "    return filtered_fine_amounts if filtered_fine_amounts else None\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "pdf_folder = \"/root/pdf_downloads\"  # Change to your actual folder\n",
        "\n",
        "# 1. Initialize BERTopic model\n",
        "topic_model = BERTopic()\n",
        "document_data = []  # Placeholder for the data\n",
        "\n",
        "# 2. Process the PDFs to get the data. This step now ONLY extracts and preprocesses data.\n",
        "#    It does NOT perform summarization or topic modeling.\n",
        "for filename in os.listdir(pdf_folder):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(pdf_folder, filename)\n",
        "        print(f\"Processing {filename}...\")\n",
        "\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        processed_text = preprocess_text(text)\n",
        "        entities = extract_entities(text)\n",
        "\n",
        "        # Extract fine amounts\n",
        "        fine_amounts = detect_fines(text)\n",
        "        if fine_amounts:\n",
        "            entities[\"Fine Amount\"] = \", \".join(fine_amounts)\n",
        "\n",
        "        document_data.append({\n",
        "            \"Filename\": filename,\n",
        "            \"Document Text\": processed_text,\n",
        "            \"Case Number\": entities[\"Case Number\"],\n",
        "            \"Business Name\": entities[\"Business Name\"],\n",
        "            \"Fine Amount\": entities[\"Fine Amount\"],\n",
        "            \"Date\": entities[\"Date\"]\n",
        "        })\n",
        "\n",
        "# 3. Now fit the BERTopic model with actual data.\n",
        "all_texts = [doc[\"Document Text\"] for doc in document_data]\n",
        "topic_model.fit(all_texts)\n",
        "\n",
        "# 4. Now perform summarization, including topic modeling for each document.\n",
        "for doc in document_data:\n",
        "    # Summarization\n",
        "    summary_programmatic, summary_user = summarize_case(doc[\"Document Text\"], topic_model)  # Pass document text here\n",
        "    doc[\"Summary Programmatic\"] = summary_programmatic  # Add summaries to the document data\n",
        "    doc[\"Summary User\"] = summary_user\n",
        "\n",
        "    topics, _ = topic_model.transform([doc[\"Document Text\"]])\n",
        "    doc[\"Dominant Topic\"] = topic_model.get_topic(topics[0])\n",
        "\n",
        "# Store data in DataFrame and save as CSV\n",
        "df = pd.DataFrame(document_data)\n",
        "df.to_csv(\"cra_case_summaries.csv\", index=False)\n",
        "# Display the 'Fine Amount' column\n",
        "print(df[['Filename', 'Fine Amount']])  # Select and display Filename and Fine Amount columns\n",
        "# --- Cosine Similarity Analysis ---\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Filter out empty summaries\n",
        "df_filtered = df[df['Summary Programmatic'] != \"\"]\n",
        "# If df_filtered is empty, there are no summaries to compare, you'll need to debug why\n",
        "if df_filtered.empty:\n",
        "    print(\"No summaries found for similarity analysis. Check summarization results.\")\n",
        "else:\n",
        "    tfidf_matrix = vectorizer.fit_transform(df_filtered['Summary Programmatic'])\n",
        "\n",
        "    cosine_similarities = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "    # Find similar documents\n",
        "    similarity_threshold = 0.7\n",
        "    similar_docs = {}\n",
        "\n",
        "    for i, filename in enumerate(df_filtered[\"Filename\"]):  # Iterate through filtered DataFrame\n",
        "        similar_indices = [\n",
        "            j for j, similarity in enumerate(cosine_similarities[i])\n",
        "            if similarity > similarity_threshold and j != i\n",
        "        ]\n",
        "        similar_docs[filename] = df_filtered.iloc[similar_indices][\"Filename\"].tolist()  # Get filenames from filtered DataFrame\n",
        "\n",
        "    # Display Similar Documents\n",
        "    print(\"\\nSimilar Cases Found:\")\n",
        "    for doc, similar_cases in similar_docs.items():\n",
        "        if similar_cases:\n",
        "            print(f\"{doc} is similar to: {', '.join(similar_cases)}\")\n",
        "        else:\n",
        "            print(f\"{doc} has no strong similarities.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNhxMZmNxhxK",
        "outputId": "334f343e-d0fa-4a48-88a2-f5af4b53d313"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.25.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: summa in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.11/dist-packages (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.8.40)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (3.3.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.5.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (9.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.47.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.27.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.12.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.12.14)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Premier-Botanics-LLC-AUMB000106-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf...\n",
            "Processing Smoke-UP-Farms-LLC-dba-Tree-of-Life-Cannabis-AUGC001018-Consent-Order-and-Stipulation-and-Formal-Com.pdf...\n",
            "Processing STAR-BUDZ-PROVISIONING-CENTER-LLC-dba-Star-Budz-AUR000611-Consent-Order-and-Stipulation-and-Formal-C.pdf...\n",
            "Processing Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000270-Consent-Order-and-Stipulation-and-For.pdf...\n",
            "Processing Revolution-Strains-Inc-dba-Nirvana-Center-Processing-PR000295-Consent-Order-and-Stipulation-and-Form.pdf...\n",
            "Processing Revolution-Strains-Inc-dba-Nirvana-Center-Processing-AUP000286-Consent-Order-and-Stipulation-and-For.pdf...\n",
            "Processing DJR-Michigan-Properties-LLC-dba-High-Level-Health-AUGC000331-Consent-Order-and-Stipulation-and-Forma.pdf...\n",
            "Processing DJR-Michigan-Properties-LLC-dba-High-Level-Health-GRC000182-Consent-Order-and-Stipulation-and-Formal.pdf...\n",
            "Processing 305-Farms-LLC-AUGC000793-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf...\n",
            "Processing DJR-Michigan-Properties-LLC-dba-High-Level-Health-AUGC000302-Consent-Order-and-Stipulation-and-Forma.pdf...\n",
            "Processing 664-Vassar-LLC-dba-Premier-Saginaw-III-AUR000547-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf...\n",
            "Processing JARS-Holdings-LLC-dba-JARS-Cannabis-AUR001187-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf...\n",
            "Processing 420-Medz-LLC-GRC000869-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf...\n",
            "Processing The-Wellflower-Ypsilanti-LLC-AUR000665-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf...\n",
            "Processing Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000267-Consent-Order-and-Stipulation-and-For.pdf...\n",
            "Processing Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGEX000136-Consent-Order-and-Stipulation-and-Fo.pdf...\n",
            "Processing 222-Biz-2-LLC-dba-Mystic-Cannabis-of-Memphis-AUR001055-Consent-Order-and-Stipulation-and-Formal-Comp.pdf...\n",
            "Processing 325HTD-Growers-LLC-dba-Amber-Waves-Cannabis-Co-AUGC001093-Consent-Order-and-Stipulation-and-Formal-C.pdf...\n",
            "Processing Adams-Family-Farms-LLC-AUGC000480-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf...\n",
            "Processing HMFM-Holdings-LLC-AUGC001158-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf...\n",
            "Processing Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000152-Consent-Order-and-Stipulation-and-For.pdf...\n",
            "                                             Filename  \\\n",
            "0   Premier-Botanics-LLC-AUMB000106-Consent-Order-...   \n",
            "1   Smoke-UP-Farms-LLC-dba-Tree-of-Life-Cannabis-A...   \n",
            "2   STAR-BUDZ-PROVISIONING-CENTER-LLC-dba-Star-Bud...   \n",
            "3   Compassionate-Advisors--Pinconning-LLC-dba-Pin...   \n",
            "4   Revolution-Strains-Inc-dba-Nirvana-Center-Proc...   \n",
            "5   Revolution-Strains-Inc-dba-Nirvana-Center-Proc...   \n",
            "6   DJR-Michigan-Properties-LLC-dba-High-Level-Hea...   \n",
            "7   DJR-Michigan-Properties-LLC-dba-High-Level-Hea...   \n",
            "8   305-Farms-LLC-AUGC000793-Consent-Order-and-Sti...   \n",
            "9   DJR-Michigan-Properties-LLC-dba-High-Level-Hea...   \n",
            "10  664-Vassar-LLC-dba-Premier-Saginaw-III-AUR0005...   \n",
            "11  JARS-Holdings-LLC-dba-JARS-Cannabis-AUR001187-...   \n",
            "12  420-Medz-LLC-GRC000869-Consent-Order-and-Stipu...   \n",
            "13  The-Wellflower-Ypsilanti-LLC-AUR000665-Consent...   \n",
            "14  Compassionate-Advisors--Pinconning-LLC-dba-Pin...   \n",
            "15  Compassionate-Advisors--Pinconning-LLC-dba-Pin...   \n",
            "16  222-Biz-2-LLC-dba-Mystic-Cannabis-of-Memphis-A...   \n",
            "17  325HTD-Growers-LLC-dba-Amber-Waves-Cannabis-Co...   \n",
            "18  Adams-Family-Farms-LLC-AUGC000480-Consent-Orde...   \n",
            "19  HMFM-Holdings-LLC-AUGC001158-Consent-Order-and...   \n",
            "20  Compassionate-Advisors--Pinconning-LLC-dba-Pin...   \n",
            "\n",
            "                 Fine Amount  \n",
            "0                   7,000.00  \n",
            "1                   33.27957  \n",
            "2                   33.27001  \n",
            "3      419 E Pinconning Road  \n",
            "4                  25,000.00  \n",
            "5                  25,000.00  \n",
            "6                    1125.00  \n",
            "7                 33.27407(4  \n",
            "8                  10,000.00  \n",
            "9                   1,125.00  \n",
            "10                      8.00  \n",
            "11                      None  \n",
            "12                  8,000.00  \n",
            "13                     15.00  \n",
            "14     419 E Pinconning Road  \n",
            "15     419 E Pinconning Road  \n",
            "16                  3,500.00  \n",
            "17  1A40503000339C9000002530  \n",
            "18                     4,096  \n",
            "19                  7,000.00  \n",
            "20     419 E Pinconning Road  \n",
            "\n",
            "Similar Cases Found:\n",
            "Premier-Botanics-LLC-AUMB000106-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf is similar to: HMFM-Holdings-LLC-AUGC001158-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf\n",
            "Smoke-UP-Farms-LLC-dba-Tree-of-Life-Cannabis-AUGC001018-Consent-Order-and-Stipulation-and-Formal-Com.pdf has no strong similarities.\n",
            "STAR-BUDZ-PROVISIONING-CENTER-LLC-dba-Star-Budz-AUR000611-Consent-Order-and-Stipulation-and-Formal-C.pdf has no strong similarities.\n",
            "Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000270-Consent-Order-and-Stipulation-and-For.pdf is similar to: Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000267-Consent-Order-and-Stipulation-and-For.pdf, Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGEX000136-Consent-Order-and-Stipulation-and-Fo.pdf, Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000152-Consent-Order-and-Stipulation-and-For.pdf\n",
            "Revolution-Strains-Inc-dba-Nirvana-Center-Processing-PR000295-Consent-Order-and-Stipulation-and-Form.pdf is similar to: Revolution-Strains-Inc-dba-Nirvana-Center-Processing-AUP000286-Consent-Order-and-Stipulation-and-For.pdf\n",
            "Revolution-Strains-Inc-dba-Nirvana-Center-Processing-AUP000286-Consent-Order-and-Stipulation-and-For.pdf is similar to: Revolution-Strains-Inc-dba-Nirvana-Center-Processing-PR000295-Consent-Order-and-Stipulation-and-Form.pdf\n",
            "DJR-Michigan-Properties-LLC-dba-High-Level-Health-AUGC000331-Consent-Order-and-Stipulation-and-Forma.pdf is similar to: DJR-Michigan-Properties-LLC-dba-High-Level-Health-GRC000182-Consent-Order-and-Stipulation-and-Formal.pdf, DJR-Michigan-Properties-LLC-dba-High-Level-Health-AUGC000302-Consent-Order-and-Stipulation-and-Forma.pdf\n",
            "DJR-Michigan-Properties-LLC-dba-High-Level-Health-GRC000182-Consent-Order-and-Stipulation-and-Formal.pdf is similar to: DJR-Michigan-Properties-LLC-dba-High-Level-Health-AUGC000331-Consent-Order-and-Stipulation-and-Forma.pdf, DJR-Michigan-Properties-LLC-dba-High-Level-Health-AUGC000302-Consent-Order-and-Stipulation-and-Forma.pdf\n",
            "305-Farms-LLC-AUGC000793-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf has no strong similarities.\n",
            "DJR-Michigan-Properties-LLC-dba-High-Level-Health-AUGC000302-Consent-Order-and-Stipulation-and-Forma.pdf is similar to: DJR-Michigan-Properties-LLC-dba-High-Level-Health-AUGC000331-Consent-Order-and-Stipulation-and-Forma.pdf, DJR-Michigan-Properties-LLC-dba-High-Level-Health-GRC000182-Consent-Order-and-Stipulation-and-Formal.pdf\n",
            "664-Vassar-LLC-dba-Premier-Saginaw-III-AUR000547-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf has no strong similarities.\n",
            "JARS-Holdings-LLC-dba-JARS-Cannabis-AUR001187-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf has no strong similarities.\n",
            "420-Medz-LLC-GRC000869-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf has no strong similarities.\n",
            "The-Wellflower-Ypsilanti-LLC-AUR000665-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf has no strong similarities.\n",
            "Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000267-Consent-Order-and-Stipulation-and-For.pdf is similar to: Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000270-Consent-Order-and-Stipulation-and-For.pdf, Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGEX000136-Consent-Order-and-Stipulation-and-Fo.pdf, Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000152-Consent-Order-and-Stipulation-and-For.pdf\n",
            "Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGEX000136-Consent-Order-and-Stipulation-and-Fo.pdf is similar to: Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000270-Consent-Order-and-Stipulation-and-For.pdf, Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000267-Consent-Order-and-Stipulation-and-For.pdf, Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000152-Consent-Order-and-Stipulation-and-For.pdf\n",
            "222-Biz-2-LLC-dba-Mystic-Cannabis-of-Memphis-AUR001055-Consent-Order-and-Stipulation-and-Formal-Comp.pdf has no strong similarities.\n",
            "325HTD-Growers-LLC-dba-Amber-Waves-Cannabis-Co-AUGC001093-Consent-Order-and-Stipulation-and-Formal-C.pdf has no strong similarities.\n",
            "Adams-Family-Farms-LLC-AUGC000480-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf has no strong similarities.\n",
            "HMFM-Holdings-LLC-AUGC001158-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf is similar to: Premier-Botanics-LLC-AUMB000106-Consent-Order-and-Stipulation-and-Formal-Complaint.pdf\n",
            "Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000152-Consent-Order-and-Stipulation-and-For.pdf is similar to: Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000270-Consent-Order-and-Stipulation-and-For.pdf, Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGC000267-Consent-Order-and-Stipulation-and-For.pdf, Compassionate-Advisors--Pinconning-LLC-dba-Pincanna-AUGEX000136-Consent-Order-and-Stipulation-and-Fo.pdf\n"
          ]
        }
      ]
    }
  ]
}